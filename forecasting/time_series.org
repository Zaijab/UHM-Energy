#+TITLE: Forecasting Time Series
#+PROPERTY: header-args:python3 :exports "results" :session weather :pandoc t :async yes

* Time series forecasting
** The Dataset
*** Setup

Import Python Modules

#+BEGIN_SRC python3 :results silent
import os
import datetime
import IPython
import IPython.display
import matplotlib as mpl
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf

mpl.rcParams['figure.figsize'] = (14, 8)
mpl.rcParams['axes.grid'] = False
#+END_SRC


*** Importing and Visualizing the Data
#+BEGIN_SRC python3
df = pd.read_csv("../data/power_average.csv")
df["day_type"] = pd.Categorical(df["day_type"]).codes
df = df[df["building_name"] == "ARCHITECTURE BLDG"]
df.pop('building_name')
df = df[5::4]
date_time = pd.to_datetime(df.pop('datetime'))
df.head()
#+END_SRC

#+RESULTS:
:RESULTS:
|       | kw_average | temperature_c | humidity | solar_radiation_wm2 | day_type |
|-------+------------+---------------+----------+---------------------+----------|
| 92295 | 66.800000  | 26.64         | 58.2     | 894.1               | 2        |
| 92299 | 68.533333  | 25.95         | 59.7     | 827.6               | 2        |
| 92303 | 67.723333  | 26.38         | 60.4     | 610.6               | 2        |
| 92307 | 62.490000  | 26.16         | 60.1     | 194.6               | 2        |
| 92311 | 65.658889  | 25.16         | 63.8     | 66.5                | 2        |
:END:

Here is the evolution of a few features over time:

#+BEGIN_SRC python3
plot_cols = df.columns
plot_features = df[plot_cols]
plot_features.index = date_time
_ = plot_features.plot(subplots=True)

plot_features = df[plot_cols][:480]
plot_features.index = date_time[:480]
_ = plot_features.plot(subplots=True)
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/b1acff6effcdaba1011e09335ac6f47280f2fe10.png]]
[[file:./.ob-jupyter/a15a14f26651bdee564d55e9335e2bb55d6039ec.png]]
:END:


*** Inspect and cleanup

#+BEGIN_SRC python3
df.describe().transpose()
#+END_SRC

#+RESULTS:
:RESULTS:
|                     | count  | mean       | std        | min       | 25%       | 50%       | 75%      | max         |
|---------------------+--------+------------+------------+-----------+-----------+-----------+----------+-------------|
| kw_average          | 4614.0 | 46.743111  | 18.040367  | 18.493333 | 32.241389 | 37.572222 | 63.7075  | 91.801111   |
| temperature_c       | 4614.0 | 24.845336  | 2.017573   | 18.280000 | 23.530000 | 24.790000 | 26.1900  | 31.570000   |
| humidity            | 4614.0 | 65.133528  | 7.464909   | 40.500000 | 60.100000 | 65.800000 | 69.9000  | 88.300000   |
| solar_radiation_wm2 | 4614.0 | 271.835566 | 372.560301 | 0.000000  | 0.700000  | 22.800000 | 502.7250 | 1434.600000 |
| day_type            | 4614.0 | 3.201127   | 1.865715   | 0.000000  | 2.000000  | 2.000000  | 5.0000   | 6.000000    |
:END:


*** Feature engineering

Before diving in to build a model, it's important to understand your
data and be sure that you're passing the model appropriately formatted
data.


#+BEGIN_SRC python3
timestamp_s = date_time.map(pd.Timestamp.timestamp)
fft = tf.signal.rfft(df['kw_average'])
f_per_dataset = np.arange(0, len(fft))

n_samples_h = len(df['kw_average'])
hours_per_year = 24*365.2524
years_per_dataset = n_samples_h/(hours_per_year)

f_per_year = f_per_dataset/years_per_dataset
plt.step(f_per_year, np.abs(fft))
plt.xscale('log')
plt.ylim(0, np.max(np.abs(fft[1:]))+1000)
plt.xlim([0.1, max(plt.xlim())])
plt.xticks([1, 12, 52, 365.2524], labels=['1/Year', '1/Month', '1/Week', '1/day'])
_ = plt.xlabel('Frequency (log scale)')
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/0825767fd7ab4d68eb9f2aae8bd6a045d8022ce5.png]]


*** Split the data
    :PROPERTIES:
    :CUSTOM_ID: split-the-data
    :END:
You'll use a =(70%, 20%, 10%)= split for the training, validation, and
test sets. Note the data is *not* being randomly shuffled before
splitting. This is for two reasons:

1. It ensures that chopping the data into windows of consecutive samples
   is still possible.
2. It ensures that the validation/test results are more realistic, being
   evaluated on the data collected after the model was trained.

#+BEGIN_SRC python3
column_indices = {name: i for i, name in enumerate(df.columns)}

n = len(df)
train_df = df[0:int(n*0.7)]
val_df = df[int(n*0.7):int(n*0.9)]
test_df = df[int(n*0.9):]

num_features = df.shape[1]
#+END_SRC

#+RESULTS:


*** Normalize the data
    :PROPERTIES:
    :CUSTOM_ID: normalize-the-data
    :END:
It is important to scale features before training a neural network.
Normalization is a common way of doing this scaling: subtract the mean
and divide by the standard deviation of each feature.

The mean and standard deviation should only be computed using the
training data so that the models have no access to the values in the
validation and test sets.

It's also arguable that the model shouldn't have access to future values
in the training set when training, and that this normalization should be
done using moving averages. That's not the focus of this tutorial, and
the validation and test sets ensure that you get (somewhat) honest
metrics. So, in the interest of simplicity this tutorial uses a simple
average.

#+BEGIN_SRC python3
train_mean = train_df.mean()
train_std = train_df.std()

train_df = (train_df - train_mean) / train_std
val_df = (val_df - train_mean) / train_std
test_df = (test_df - train_mean) / train_std

df_std = (df - train_mean) / train_std
df_std = df_std.melt(var_name='Column', value_name='Normalized')
plt.figure(figsize=(12, 6))
ax = sns.violinplot(x='Column', y='Normalized', data=df_std)
_ = ax.set_xticklabels(df.keys(), rotation=90)
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/b9532287742b62577ba6c7613b5620629139f548.png]]


** Data windowing
   :PROPERTIES:
   :CUSTOM_ID: data-windowing
   :END:
The models in this tutorial will make a set of predictions based on a
window of consecutive samples from the data.

The main features of the input windows are:

- The width (number of time steps) of the input and label windows.
- The time offset between them.
- Which features are used as inputs, labels, or both.

This tutorial builds a variety of models (including Linear, DNN, CNN and
RNN models), and uses them for both:

- /Single-output/, and /multi-output/ predictions.
- /Single-time-step/ and /multi-time-step/ predictions.

This section focuses on implementing the data windowing so that it can
be reused for all of those models.

Depending on the task and type of model you may want to generate a
variety of data windows. Here are some SRCs:

1. For SRC, to make a single prediction 24 hours into the future,
   given 24 hours of history, you might define a window like this:

#+caption: One prediction 24 hours into the future.
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/raw_window_24h.png?raw=1]]

2. A model that makes a prediction one hour into the future, given six
   hours of history, would need a window like this:

#+caption: One prediction one hour into the future.
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/raw_window_1h.png?raw=1]]

The rest of this section defines a =WindowGenerator= class. This class
can:

1. Handle the indexes and offsets as shown in the diagrams above.
2. Split windows of features into =(features, labels)= pairs.
3. Plot the content of the resulting windows.
4. Efficiently generate batches of these windows from the training,
   evaluation, and test data, using =tf.data.Dataset=s.

*** 1. Indexes and offsets
    :PROPERTIES:
    :CUSTOM_ID: indexes-and-offsets
    :END:
Start by creating the =WindowGenerator= class. The =__init__= method
includes all the necessary logic for the input and label indices.

It also takes the training, evaluation, and test DataFrames as input.
These will be converted to =tf.data.Dataset=s of windows later.

#+BEGIN_SRC python3
  class WindowGenerator():
    def __init__(self, input_width, label_width, shift,
                 train_df=train_df, val_df=val_df, test_df=test_df,
                 label_columns=None):
      # Store the raw data.
      self.train_df = train_df
      self.val_df = val_df
      self.test_df = test_df

      # Work out the label column indices.
      self.label_columns = label_columns
      if label_columns is not None:
        self.label_columns_indices = {name: i for i, name in
                                      enumerate(label_columns)}
      self.column_indices = {name: i for i, name in
                             enumerate(train_df.columns)}

      # Work out the window parameters.
      self.input_width = input_width
      self.label_width = label_width
      self.shift = shift

      self.total_window_size = input_width + shift

      self.input_slice = slice(0, input_width)
      self.input_indices = np.arange(self.total_window_size)[self.input_slice]

      self.label_start = self.total_window_size - self.label_width
      self.labels_slice = slice(self.label_start, None)
      self.label_indices = np.arange(self.total_window_size)[self.labels_slice]

    def __repr__(self):
      return '\n'.join([
          f'Total window size: {self.total_window_size}',
          f'Input indices: {self.input_indices}',
          f'Label indices: {self.label_indices}',
          f'Label column name(s): {self.label_columns}'])
#+END_SRC

#+RESULTS:

Here is code to create the 2 windows shown in the diagrams at the start
of this section:

#+BEGIN_SRC python3
  w1 = WindowGenerator(input_width=24, label_width=1, shift=24,
                       label_columns=['kw_average'])
  w1
#+END_SRC

#+RESULTS:
: Total window size: 48
: Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]
: Label indices: [47]
: Label column name(s): ['kw_average']


#+BEGIN_SRC python3
  w2 = WindowGenerator(input_width=24*7, label_width=1, shift=1,
                       label_columns=['kw_average'])
  w2
#+END_SRC

#+RESULTS:
#+begin_example
Total window size: 169
Input indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167]
Label indices: [168]
Label column name(s): ['kw_average']
#+end_example


*** 2. Split
    :PROPERTIES:
    :CUSTOM_ID: split
    :END:
Given a list of consecutive inputs, the =split_window= method will
convert them to a window of inputs and a window of labels.

The SRC =w2= you define earlier will be split like this:

#+caption: The initial window is all consecutive samples, this splits it
into an (inputs, labels) pairs
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/split_window.png?raw=1]]

This diagram doesn't show the =features= axis of the data, but this
=split_window= function also handles the =label_columns= so it can be
used for both the single output and multi-output SRCs.

#+BEGIN_SRC python3
  def split_window(self, features):
    inputs = features[:, self.input_slice, :]
    labels = features[:, self.labels_slice, :]
    if self.label_columns is not None:
      labels = tf.stack(
          [labels[:, :, self.column_indices[name]] for name in self.label_columns],
          axis=-1)

    # Slicing doesn't preserve static shape information, so set the shapes
    # manually. This way the `tf.data.Datasets` are easier to inspect.
    inputs.set_shape([None, self.input_width, None])
    labels.set_shape([None, self.label_width, None])

    return inputs, labels

  WindowGenerator.split_window = split_window
#+END_SRC

#+RESULTS:

Try it out:

#+BEGIN_SRC python3
  # Stack three slices, the length of the total window.
  example_window = tf.stack([np.array(train_df[:w2.total_window_size]),
                             np.array(train_df[100:100+w2.total_window_size]),
                             np.array(train_df[200:200+w2.total_window_size])])

  example_inputs, example_labels = w2.split_window(example_window)

  print('All shapes are: (batch, time, features)')
  print(f'Window shape: {example_window.shape}')
  print(f'Inputs shape: {example_inputs.shape}')
  print(f'Labels shape: {example_labels.shape}')
#+END_SRC

#+RESULTS:
: All shapes are: (batch, time, features)
: Window shape: (3, 169, 5)
: Inputs shape: (3, 168, 5)
: Labels shape: (3, 1, 1)


Typically, data in TensorFlow is packed into arrays where the outermost
index is across SRCs (the "batch" dimension). The middle indices are
the "time" or "space" (width, height) dimension(s). The innermost
indices are the features.

The code above took a batch of three 7-time step windows with 19
features at each time step. It splits them into a batch of 6-time step
19-feature inputs, and a 1-time step 1-feature label. The label only has
one feature because the =WindowGenerator= was initialized with
=label_columns=['kw_average']=. Initially, this tutorial will build
models that predict single output labels.


*** 3. Plot
    :PROPERTIES:
    :CUSTOM_ID: plot
    :END:
Here is a plot method that allows a simple visualization of the split
window:

#+BEGIN_SRC python3
  w2.example = example_inputs, example_labels
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python3
  def plot(self, model=None, plot_col='kw_average', max_subplots=3):
    inputs, labels = self.example
    plt.figure(figsize=(12, 8))
    plot_col_index = self.column_indices[plot_col]
    max_n = min(max_subplots, len(inputs))
    for n in range(max_n):
      plt.subplot(max_n, 1, n+1)
      plt.ylabel(f'{plot_col} [normed]')
      plt.plot(self.input_indices, inputs[n, :, plot_col_index],
               label='Inputs', marker='.', zorder=-10)

      if self.label_columns:
        label_col_index = self.label_columns_indices.get(plot_col, None)
      else:
        label_col_index = plot_col_index

      if label_col_index is None:
        continue

      plt.scatter(self.label_indices, labels[n, :, label_col_index],
                  edgecolors='k', label='Labels', c='#2ca02c', s=64)
      if model is not None:
        predictions = model(inputs)
        plt.scatter(self.label_indices, predictions[n, :, label_col_index],
                    marker='X', edgecolors='k', label='Predictions',
                    c='#ff7f0e', s=64)

      if n == 0:
        plt.legend()

    plt.xlabel('Time [h]')

  WindowGenerator.plot = plot
#+END_SRC

#+RESULTS:

This plot aligns inputs, labels, and (later) predictions based on the
time that the item refers to:

#+BEGIN_SRC python3
  w2.plot()
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/169313f46db7fb4472b6ec5f9bc431a192fd9b00.png]]

#+caption: png
[[file:time_series_files/time_series_51_0.png]]

You can plot the other columns, but the SRC window =w2=
configuration only has labels for the =kw_average= column.

#+BEGIN_SRC python3
  w2.plot(plot_col='temperature_c')
#+END_SRC

#+RESULTS:
[[file:./.ob-jupyter/f427ede71f8fb19e31d5ea455db0edd316448413.png]]

#+caption: png
[[file:time_series_files/time_series_53_0.png]]


*** 4. Create =tf.data.Dataset=s
    :PROPERTIES:
    :CUSTOM_ID: create-tf.data.datasets
    :END:
Finally, this =make_dataset= method will take a time series DataFrame
and convert it to a =tf.data.Dataset= of =(input_window, label_window)=
pairs using the =tf.keras.utils.timeseries_dataset_from_array= function:

#+BEGIN_SRC python3
  def make_dataset(self, data):
    data = np.array(data, dtype=np.float32)
    ds = tf.keras.utils.timeseries_dataset_from_array(
        data=data,
        targets=None,
        sequence_length=self.total_window_size,
        sequence_stride=1,
        shuffle=True,
        batch_size=32,)

    ds = ds.map(self.split_window)

    return ds

  WindowGenerator.make_dataset = make_dataset
#+END_SRC

#+RESULTS:

The =WindowGenerator= object holds training, validation, and test data.

Add properties for accessing them as =tf.data.Dataset=s using the
=make_dataset= method you defined earlier. Also, add a standard SRC
batch for easy access and plotting:

#+BEGIN_SRC python3
  @property
  def train(self):
    return self.make_dataset(self.train_df)

  @property
  def val(self):
    return self.make_dataset(self.val_df)

  @property
  def test(self):
    return self.make_dataset(self.test_df)

  @property
  def example(self):
    """Get and cache an example batch of `inputs, labels` for plotting."""
    result = getattr(self, '_example', None)
    if result is None:
      # No example batch was found, so get one from the `.train` dataset
      result = next(iter(self.train))
      # And cache it for next time
      self._example = result
    return result

  WindowGenerator.train = train
  WindowGenerator.val = val
  WindowGenerator.test = test
  WindowGenerator.example = example
#+END_SRC

#+RESULTS:

Now, the =WindowGenerator= object gives you access to the
=tf.data.Dataset= objects, so you can easily iterate over the data.

The =Dataset.element_spec= property tells you the structure, data types,
and shapes of the dataset elements.

#+BEGIN_SRC python3
  # Each element is an (inputs, label) pair.
  w2.train.element_spec
#+END_SRC

#+RESULTS:
| TensorSpec | (shape= (None 168 5) dtype=tf.float32 name=None) | TensorSpec | (shape= (None 1 1) dtype=tf.float32 name=None) |


Iterating over a =Dataset= yields concrete batches:

#+BEGIN_SRC python3
  for example_inputs, example_labels in w2.train.take(1):
    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')
    print(f'Labels shape (batch, time, features): {example_labels.shape}')
#+END_SRC

#+RESULTS:
: Inputs shape (batch, time, features): (32, 168, 5)
: Labels shape (batch, time, features): (32, 1, 1)


** Multi-step models
   :PROPERTIES:
   :CUSTOM_ID: multi-step-models
   :END:
Both the single-output and multiple-output models in the previous
sections made *single time step predictions*, one hour into the future.

This section looks at how to expand these models to make *multiple time
step predictions*.

In a multi-step prediction, the model needs to learn to predict a range
of future values. Thus, unlike a single step model, where only a single
future point is predicted, a multi-step model predicts a sequence of the
future values.

There are two rough approaches to this:

1. Single shot predictions where the entire time series is predicted at
   once.
2. Autoregressive predictions where the model only makes single step
   predictions and its output is fed back as its input.

In this section all the models will predict *all the features across all
output time steps*.

For the multi-step model, the training data again consists of hourly
samples. However, here, the models will learn to predict 24 hours into
the future, given 24 hours of the past.

Here is a =Window= object that generates these slices from the dataset:

#+BEGIN_SRC python3
  OUT_STEPS = 24
  multi_window = WindowGenerator(input_width=24,
                                 label_width=OUT_STEPS,
                                 shift=OUT_STEPS)

  multi_window.plot()
  multi_window
#+END_SRC

#+RESULTS:
:RESULTS:
: Total window size: 48
: Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]
: Label indices: [24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47]
: Label column name(s): None
[[file:./.ob-jupyter/a0bcdcf3f69de7f78253a3f4ece2263f5f53501b.png]]
:END:


*** Baselines
    :PROPERTIES:
    :CUSTOM_ID: baselines
    :END:
A simple baseline for this task is to repeat the last input time step
for the required number of output time steps:

#+caption: Repeat the last input, for each output step
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_last.png?raw=1]]

#+BEGIN_SRC python3
  class MultiStepLastBaseline(tf.keras.Model):
    def call(self, inputs):
      return tf.tile(inputs[:, -1:, :], [1, OUT_STEPS, 1])

  last_baseline = MultiStepLastBaseline()
  last_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),
                        metrics=[tf.keras.metrics.MeanAbsoluteError()])

  multi_val_performance = {}
  multi_performance = {}

  multi_val_performance['Last'] = last_baseline.evaluate(multi_window.val)
  multi_performance['Last'] = last_baseline.evaluate(multi_window.test, verbose=0)
  multi_window.plot(last_baseline)
#+END_SRC

#+RESULTS:
:RESULTS:
: 28/28 [==============================] - 0s 565us/step - loss: 1.4235 - mean_absolute_error: 0.8203
[[file:./.ob-jupyter/08349251faa954da2c9083e9fd08c492e880f778.png]]
:END:


Since this task is to predict 24 hours into the future, given 24 hours
of the past, another simple approach is to repeat the previous day,
assuming tomorrow will be similar:

#+caption: Repeat the previous day
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_repeat.png?raw=1]]

#+BEGIN_SRC python3
  class RepeatBaseline(tf.keras.Model):
    def call(self, inputs):
      return inputs

  repeat_baseline = RepeatBaseline()
  repeat_baseline.compile(loss=tf.keras.losses.MeanSquaredError(),
                          metrics=[tf.keras.metrics.MeanAbsoluteError()])

  multi_val_performance['Repeat'] = repeat_baseline.evaluate(multi_window.val)
  multi_performance['Repeat'] = repeat_baseline.evaluate(multi_window.test, verbose=0)
  multi_window.plot(repeat_baseline)
#+END_SRC

#+RESULTS:
:RESULTS:
: 28/28 [==============================] - 0s 560us/step - loss: 0.8651 - mean_absolute_error: 0.5289
[[file:./.ob-jupyter/f40e920f49e030bc6069cfeb6c89a3628fd71996.png]]
:END:


*** Advanced: Autoregressive model
    :PROPERTIES:
    :CUSTOM_ID: advanced-autoregressive-model
    :END:
The above models all predict the entire output sequence in a single
step.

In some cases it may be helpful for the model to decompose this
prediction into individual time steps. Then, each model's output can be
fed back into itself at each step and predictions can be made
conditioned on the previous one, like in the classic Generating
Sequences With Recurrent Neural Networks.

One clear advantage to this style of model is that it can be set up to
produce output with a varying length.

You could take any of the single-step multi-output models trained in the
first half of this tutorial and run in an autoregressive feedback loop,
but here you'll focus on building a model that's been explicitly trained
to do that.

#+caption: Feedback a model's output to its input
[[https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/images/multistep_autoregressive.png?raw=1]]

**** RNN
     :PROPERTIES:
     :CUSTOM_ID: rnn-2
     :END:
This tutorial only builds an autoregressive RNN model, but this pattern
could be applied to any model that was designed to output a single time
step.

The model will have the same basic form as the single-step LSTM models
from earlier: a =tf.keras.layers.LSTM= layer followed by a
=tf.keras.layers.Dense= layer that converts the =LSTM= layer's outputs
to model predictions.

A =tf.keras.layers.LSTM= is a =tf.keras.layers.LSTMCell= wrapped in the
higher level =tf.keras.layers.RNN= that manages the state and sequence
results for you (Check out the
[[https://www.tensorflow.org/guide/keras/rnn][Recurrent Neural Networks
(RNN) with Keras]] guide for details).

In this case, the model has to manually manage the inputs for each step,
so it uses =tf.keras.layers.LSTMCell= directly for the lower level,
single time step interface.

#+BEGIN_SRC python3
  class FeedBack(tf.keras.Model):
    def __init__(self, units, out_steps):
      super().__init__()
      self.out_steps = out_steps
      self.units = units
      self.lstm_cell = tf.keras.layers.LSTMCell(units)
      # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.
      self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)
      self.dense = tf.keras.layers.Dense(num_features)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python3
  feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)
#+END_SRC

#+RESULTS:

The first method this model needs is a =warmup= method to initialize its
internal state based on the inputs. Once trained, this state will
capture the relevant parts of the input history. This is equivalent to
the single-step =LSTM= model from earlier:

#+BEGIN_SRC python3
  def warmup(self, inputs):
    # inputs.shape => (batch, time, features)
    # x.shape => (batch, lstm_units)
    x, *state = self.lstm_rnn(inputs)

    # predictions.shape => (batch, features)
    prediction = self.dense(x)
    return prediction, state

  FeedBack.warmup = warmup
#+END_SRC

#+RESULTS:

This method returns a single time-step prediction and the internal state
of the =LSTM=:

#+BEGIN_SRC python3
  prediction, state = feedback_model.warmup(multi_window.example[0])
  prediction.shape
#+END_SRC

#+RESULTS:
: TensorShape([32, 5])


With the =RNN='s state, and an initial prediction you can now continue
iterating the model feeding the predictions at each step back as the
input.

The simplest approach for collecting the output predictions is to use a
Python list and a =tf.stack= after the loop.

Note: Stacking a Python list like this only works with eager-execution,
using =Model.compile(..., run_eagerly=True)= for training, or with a
fixed length output. For a dynamic output length, you would need to use
a =tf.TensorArray= instead of a Python list, and =tf.range= instead of
the Python =range=.

#+BEGIN_SRC python3
def call(self, inputs, training=None):
  # Use a TensorArray to capture dynamically unrolled outputs.
  predictions = []
  # Initialize the LSTM state.
  prediction, state = self.warmup(inputs)

  # Insert the first prediction.
  predictions.append(prediction)

  # Run the rest of the prediction steps.
  for n in range(1, self.out_steps):
    # Use the last prediction as input.
    x = prediction
    # Execute one lstm step.
    x, state = self.lstm_cell(x, states=state,
                              training=training)
    # Convert the lstm output to a prediction.
    prediction = self.dense(x)
    # Add the prediction to the output.
    predictions.append(prediction)

  # predictions.shape => (time, batch, features)
  predictions = tf.stack(predictions)
  # predictions.shape => (batch, time, features)
  predictions = tf.transpose(predictions, [1, 0, 2])
  return predictions

FeedBack.call = call
#+END_SRC

#+RESULTS:

Test run this model on the example inputs:

#+BEGIN_SRC python3
  print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)
#+END_SRC

#+RESULTS:
: Output shape (batch, time, features):  (32, 24, 5)


Now, train the model:

#+BEGIN_SRC python3
MAX_EPOCHS = 200

def compile_and_fit(model, window, patience=2):
  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',
                                                    patience=patience,
                                                    mode='min')

  model.compile(loss=tf.keras.losses.MeanSquaredError(),
                optimizer=tf.keras.optimizers.Adam(),
                metrics=[tf.keras.metrics.MeanAbsoluteError()])

  history = model.fit(window.train, epochs=MAX_EPOCHS,
                      validation_data=window.val,
                      #callbacks=[early_stopping]
                      )
  return history
history = compile_and_fit(feedback_model, multi_window)

IPython.display.clear_output()

multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)
multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)
multi_window.plot(feedback_model)
#+END_SRC

#+RESULTS:
:RESULTS:
#+begin_example
Epoch 1/200
100/100 [==============================] - 4s 10ms/step - loss: 0.2011 - mean_absolute_error: 0.3100 - val_loss: 0.3600 - val_mean_absolute_error: 0.3981
Epoch 2/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1981 - mean_absolute_error: 0.3071 - val_loss: 0.3714 - val_mean_absolute_error: 0.4007
Epoch 3/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1941 - mean_absolute_error: 0.3039 - val_loss: 0.3715 - val_mean_absolute_error: 0.3965
Epoch 4/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1937 - mean_absolute_error: 0.3030 - val_loss: 0.3658 - val_mean_absolute_error: 0.3880
Epoch 5/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1896 - mean_absolute_error: 0.2997 - val_loss: 0.3653 - val_mean_absolute_error: 0.3922
Epoch 6/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1907 - mean_absolute_error: 0.3008 - val_loss: 0.3788 - val_mean_absolute_error: 0.3976
Epoch 7/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1864 - mean_absolute_error: 0.2973 - val_loss: 0.3708 - val_mean_absolute_error: 0.3968
Epoch 8/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1888 - mean_absolute_error: 0.2986 - val_loss: 0.3604 - val_mean_absolute_error: 0.3863
Epoch 9/200
100/100 [==============================] - 1s 8ms/step - loss: 0.1878 - mean_absolute_error: 0.2976 - val_loss: 0.3640 - val_mean_absolute_error: 0.3901
Epoch 10/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1818 - mean_absolute_error: 0.2937 - val_loss: 0.3729 - val_mean_absolute_error: 0.3956
Epoch 11/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1806 - mean_absolute_error: 0.2922 - val_loss: 0.3648 - val_mean_absolute_error: 0.3875
Epoch 12/200
100/100 [==============================] - 1s 8ms/step - loss: 0.1785 - mean_absolute_error: 0.2903 - val_loss: 0.3687 - val_mean_absolute_error: 0.3905
Epoch 13/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1805 - mean_absolute_error: 0.2917 - val_loss: 0.4001 - val_mean_absolute_error: 0.4118
Epoch 14/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1755 - mean_absolute_error: 0.2879 - val_loss: 0.3756 - val_mean_absolute_error: 0.3917
Epoch 15/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1753 - mean_absolute_error: 0.2872 - val_loss: 0.3700 - val_mean_absolute_error: 0.3885
Epoch 16/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1755 - mean_absolute_error: 0.2877 - val_loss: 0.3775 - val_mean_absolute_error: 0.3933
Epoch 17/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1718 - mean_absolute_error: 0.2847 - val_loss: 0.3846 - val_mean_absolute_error: 0.3978
Epoch 18/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1698 - mean_absolute_error: 0.2831 - val_loss: 0.3764 - val_mean_absolute_error: 0.3946
Epoch 19/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1682 - mean_absolute_error: 0.2819 - val_loss: 0.3714 - val_mean_absolute_error: 0.3917
Epoch 20/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1693 - mean_absolute_error: 0.2823 - val_loss: 0.3726 - val_mean_absolute_error: 0.3940
Epoch 21/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1690 - mean_absolute_error: 0.2821 - val_loss: 0.3819 - val_mean_absolute_error: 0.3906
Epoch 22/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1696 - mean_absolute_error: 0.2822 - val_loss: 0.3681 - val_mean_absolute_error: 0.3874
Epoch 23/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1637 - mean_absolute_error: 0.2779 - val_loss: 0.3938 - val_mean_absolute_error: 0.4031
Epoch 24/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1610 - mean_absolute_error: 0.2758 - val_loss: 0.3873 - val_mean_absolute_error: 0.3935
Epoch 25/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1643 - mean_absolute_error: 0.2782 - val_loss: 0.3787 - val_mean_absolute_error: 0.3892
Epoch 26/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1623 - mean_absolute_error: 0.2761 - val_loss: 0.3972 - val_mean_absolute_error: 0.4072
Epoch 27/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1610 - mean_absolute_error: 0.2753 - val_loss: 0.4102 - val_mean_absolute_error: 0.4081
Epoch 28/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1661 - mean_absolute_error: 0.2790 - val_loss: 0.3732 - val_mean_absolute_error: 0.3903
Epoch 29/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1591 - mean_absolute_error: 0.2736 - val_loss: 0.4117 - val_mean_absolute_error: 0.4094
Epoch 30/200
100/100 [==============================] - 1s 6ms/step - loss: 0.1588 - mean_absolute_error: 0.2733 - val_loss: 0.4010 - val_mean_absolute_error: 0.4081
Epoch 31/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1587 - mean_absolute_error: 0.2735 - val_loss: 0.3959 - val_mean_absolute_error: 0.4023
Epoch 32/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1571 - mean_absolute_error: 0.2720 - val_loss: 0.3866 - val_mean_absolute_error: 0.4018
Epoch 33/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1561 - mean_absolute_error: 0.2711 - val_loss: 0.3854 - val_mean_absolute_error: 0.3959
Epoch 34/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1553 - mean_absolute_error: 0.2704 - val_loss: 0.4238 - val_mean_absolute_error: 0.4149
Epoch 35/200
100/100 [==============================] - 1s 6ms/step - loss: 0.1563 - mean_absolute_error: 0.2706 - val_loss: 0.4031 - val_mean_absolute_error: 0.4011
Epoch 36/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1517 - mean_absolute_error: 0.2673 - val_loss: 0.4077 - val_mean_absolute_error: 0.4063
Epoch 37/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1566 - mean_absolute_error: 0.2713 - val_loss: 0.4158 - val_mean_absolute_error: 0.4106
Epoch 38/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1523 - mean_absolute_error: 0.2671 - val_loss: 0.3995 - val_mean_absolute_error: 0.4013
Epoch 39/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1544 - mean_absolute_error: 0.2692 - val_loss: 0.4045 - val_mean_absolute_error: 0.4027
Epoch 40/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1561 - mean_absolute_error: 0.2700 - val_loss: 0.4287 - val_mean_absolute_error: 0.4151
Epoch 41/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1536 - mean_absolute_error: 0.2680 - val_loss: 0.4140 - val_mean_absolute_error: 0.4077
Epoch 42/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1490 - mean_absolute_error: 0.2642 - val_loss: 0.4292 - val_mean_absolute_error: 0.4201
Epoch 43/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1494 - mean_absolute_error: 0.2647 - val_loss: 0.4132 - val_mean_absolute_error: 0.4089
Epoch 44/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1476 - mean_absolute_error: 0.2627 - val_loss: 0.4120 - val_mean_absolute_error: 0.4042
Epoch 45/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1459 - mean_absolute_error: 0.2617 - val_loss: 0.4292 - val_mean_absolute_error: 0.4128
Epoch 46/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1471 - mean_absolute_error: 0.2627 - val_loss: 0.3926 - val_mean_absolute_error: 0.3915
Epoch 47/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1449 - mean_absolute_error: 0.2608 - val_loss: 0.4069 - val_mean_absolute_error: 0.4001
Epoch 48/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1480 - mean_absolute_error: 0.2622 - val_loss: 0.3916 - val_mean_absolute_error: 0.3918
Epoch 49/200
100/100 [==============================] - 1s 8ms/step - loss: 0.1424 - mean_absolute_error: 0.2587 - val_loss: 0.4190 - val_mean_absolute_error: 0.4083
Epoch 50/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1533 - mean_absolute_error: 0.2671 - val_loss: 0.4475 - val_mean_absolute_error: 0.4255
Epoch 51/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1421 - mean_absolute_error: 0.2581 - val_loss: 0.4239 - val_mean_absolute_error: 0.4082
Epoch 52/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1405 - mean_absolute_error: 0.2572 - val_loss: 0.4568 - val_mean_absolute_error: 0.4280
Epoch 53/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1436 - mean_absolute_error: 0.2593 - val_loss: 0.4369 - val_mean_absolute_error: 0.4229
Epoch 54/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1409 - mean_absolute_error: 0.2567 - val_loss: 0.4320 - val_mean_absolute_error: 0.4225
Epoch 55/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1446 - mean_absolute_error: 0.2590 - val_loss: 0.4583 - val_mean_absolute_error: 0.4332
Epoch 56/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1382 - mean_absolute_error: 0.2547 - val_loss: 0.4124 - val_mean_absolute_error: 0.4106
Epoch 57/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1381 - mean_absolute_error: 0.2544 - val_loss: 0.4299 - val_mean_absolute_error: 0.4234
Epoch 58/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1380 - mean_absolute_error: 0.2543 - val_loss: 0.4447 - val_mean_absolute_error: 0.4297
Epoch 59/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1446 - mean_absolute_error: 0.2593 - val_loss: 0.4561 - val_mean_absolute_error: 0.4249
Epoch 60/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1351 - mean_absolute_error: 0.2524 - val_loss: 0.4439 - val_mean_absolute_error: 0.4173
Epoch 61/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1331 - mean_absolute_error: 0.2503 - val_loss: 0.4578 - val_mean_absolute_error: 0.4253
Epoch 62/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1365 - mean_absolute_error: 0.2526 - val_loss: 0.4584 - val_mean_absolute_error: 0.4248
Epoch 63/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1338 - mean_absolute_error: 0.2505 - val_loss: 0.4326 - val_mean_absolute_error: 0.4075
Epoch 64/200
100/100 [==============================] - 1s 6ms/step - loss: 0.1328 - mean_absolute_error: 0.2497 - val_loss: 0.4692 - val_mean_absolute_error: 0.4339
Epoch 65/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1306 - mean_absolute_error: 0.2484 - val_loss: 0.4676 - val_mean_absolute_error: 0.4300
Epoch 66/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1362 - mean_absolute_error: 0.2520 - val_loss: 0.4425 - val_mean_absolute_error: 0.4165
Epoch 67/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1333 - mean_absolute_error: 0.2500 - val_loss: 0.4591 - val_mean_absolute_error: 0.4255
Epoch 68/200
100/100 [==============================] - 1s 6ms/step - loss: 0.1348 - mean_absolute_error: 0.2513 - val_loss: 0.4447 - val_mean_absolute_error: 0.4197
Epoch 69/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1307 - mean_absolute_error: 0.2480 - val_loss: 0.4673 - val_mean_absolute_error: 0.4285
Epoch 70/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1262 - mean_absolute_error: 0.2441 - val_loss: 0.4603 - val_mean_absolute_error: 0.4261
Epoch 71/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1290 - mean_absolute_error: 0.2463 - val_loss: 0.4463 - val_mean_absolute_error: 0.4138
Epoch 72/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1317 - mean_absolute_error: 0.2485 - val_loss: 0.4697 - val_mean_absolute_error: 0.4322
Epoch 73/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1309 - mean_absolute_error: 0.2479 - val_loss: 0.4861 - val_mean_absolute_error: 0.4364
Epoch 74/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1252 - mean_absolute_error: 0.2431 - val_loss: 0.4770 - val_mean_absolute_error: 0.4334
Epoch 75/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1258 - mean_absolute_error: 0.2426 - val_loss: 0.4441 - val_mean_absolute_error: 0.4249
Epoch 76/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1247 - mean_absolute_error: 0.2425 - val_loss: 0.4410 - val_mean_absolute_error: 0.4136
Epoch 77/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1227 - mean_absolute_error: 0.2406 - val_loss: 0.4813 - val_mean_absolute_error: 0.4309
Epoch 78/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1224 - mean_absolute_error: 0.2402 - val_loss: 0.4725 - val_mean_absolute_error: 0.4260
Epoch 79/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1289 - mean_absolute_error: 0.2459 - val_loss: 0.4508 - val_mean_absolute_error: 0.4232
Epoch 80/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1319 - mean_absolute_error: 0.2473 - val_loss: 0.4531 - val_mean_absolute_error: 0.4277
Epoch 81/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1316 - mean_absolute_error: 0.2482 - val_loss: 0.4562 - val_mean_absolute_error: 0.4178
Epoch 82/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1231 - mean_absolute_error: 0.2401 - val_loss: 0.4762 - val_mean_absolute_error: 0.4281
Epoch 83/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1216 - mean_absolute_error: 0.2387 - val_loss: 0.4828 - val_mean_absolute_error: 0.4363
Epoch 84/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1212 - mean_absolute_error: 0.2386 - val_loss: 0.4966 - val_mean_absolute_error: 0.4445
Epoch 85/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1179 - mean_absolute_error: 0.2356 - val_loss: 0.4708 - val_mean_absolute_error: 0.4238
Epoch 86/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1173 - mean_absolute_error: 0.2349 - val_loss: 0.4687 - val_mean_absolute_error: 0.4203
Epoch 87/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1254 - mean_absolute_error: 0.2423 - val_loss: 0.4786 - val_mean_absolute_error: 0.4303
Epoch 88/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1236 - mean_absolute_error: 0.2404 - val_loss: 0.4631 - val_mean_absolute_error: 0.4218
Epoch 89/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1201 - mean_absolute_error: 0.2371 - val_loss: 0.4725 - val_mean_absolute_error: 0.4282
Epoch 90/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1196 - mean_absolute_error: 0.2368 - val_loss: 0.4756 - val_mean_absolute_error: 0.4284
Epoch 91/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1166 - mean_absolute_error: 0.2339 - val_loss: 0.4930 - val_mean_absolute_error: 0.4398
Epoch 92/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1162 - mean_absolute_error: 0.2333 - val_loss: 0.4835 - val_mean_absolute_error: 0.4337
Epoch 93/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1140 - mean_absolute_error: 0.2314 - val_loss: 0.4799 - val_mean_absolute_error: 0.4267
Epoch 94/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1141 - mean_absolute_error: 0.2313 - val_loss: 0.4792 - val_mean_absolute_error: 0.4327
Epoch 95/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1145 - mean_absolute_error: 0.2316 - val_loss: 0.4747 - val_mean_absolute_error: 0.4302
Epoch 96/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1133 - mean_absolute_error: 0.2304 - val_loss: 0.4787 - val_mean_absolute_error: 0.4297
Epoch 97/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1119 - mean_absolute_error: 0.2289 - val_loss: 0.4720 - val_mean_absolute_error: 0.4252
Epoch 98/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1151 - mean_absolute_error: 0.2319 - val_loss: 0.4893 - val_mean_absolute_error: 0.4350
Epoch 99/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1154 - mean_absolute_error: 0.2320 - val_loss: 0.4787 - val_mean_absolute_error: 0.4284
Epoch 100/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1121 - mean_absolute_error: 0.2290 - val_loss: 0.4690 - val_mean_absolute_error: 0.4227
Epoch 101/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1108 - mean_absolute_error: 0.2276 - val_loss: 0.4816 - val_mean_absolute_error: 0.4277
Epoch 102/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1102 - mean_absolute_error: 0.2270 - val_loss: 0.4834 - val_mean_absolute_error: 0.4285
Epoch 103/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1254 - mean_absolute_error: 0.2386 - val_loss: 0.4187 - val_mean_absolute_error: 0.4009
Epoch 104/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1150 - mean_absolute_error: 0.2312 - val_loss: 0.4972 - val_mean_absolute_error: 0.4395
Epoch 105/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1103 - mean_absolute_error: 0.2268 - val_loss: 0.4701 - val_mean_absolute_error: 0.4246
Epoch 106/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1090 - mean_absolute_error: 0.2253 - val_loss: 0.4661 - val_mean_absolute_error: 0.4234
Epoch 107/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1091 - mean_absolute_error: 0.2254 - val_loss: 0.4678 - val_mean_absolute_error: 0.4206
Epoch 108/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1077 - mean_absolute_error: 0.2241 - val_loss: 0.4782 - val_mean_absolute_error: 0.4242
Epoch 109/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1093 - mean_absolute_error: 0.2253 - val_loss: 0.4593 - val_mean_absolute_error: 0.4159
Epoch 110/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1290 - mean_absolute_error: 0.2413 - val_loss: 0.4502 - val_mean_absolute_error: 0.4109
Epoch 111/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1120 - mean_absolute_error: 0.2274 - val_loss: 0.4553 - val_mean_absolute_error: 0.4180
Epoch 112/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1068 - mean_absolute_error: 0.2230 - val_loss: 0.4758 - val_mean_absolute_error: 0.4238
Epoch 113/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1090 - mean_absolute_error: 0.2248 - val_loss: 0.4643 - val_mean_absolute_error: 0.4246
Epoch 114/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1080 - mean_absolute_error: 0.2237 - val_loss: 0.4778 - val_mean_absolute_error: 0.4254
Epoch 115/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1094 - mean_absolute_error: 0.2249 - val_loss: 0.4672 - val_mean_absolute_error: 0.4185
Epoch 116/200
100/100 [==============================] - 1s 6ms/step - loss: 0.1057 - mean_absolute_error: 0.2215 - val_loss: 0.4670 - val_mean_absolute_error: 0.4204
Epoch 117/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1067 - mean_absolute_error: 0.2225 - val_loss: 0.4756 - val_mean_absolute_error: 0.4261
Epoch 118/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1050 - mean_absolute_error: 0.2207 - val_loss: 0.4658 - val_mean_absolute_error: 0.4183
Epoch 119/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1042 - mean_absolute_error: 0.2199 - val_loss: 0.4776 - val_mean_absolute_error: 0.4245
Epoch 120/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1122 - mean_absolute_error: 0.2274 - val_loss: 0.4360 - val_mean_absolute_error: 0.4085
Epoch 121/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1300 - mean_absolute_error: 0.2401 - val_loss: 0.4237 - val_mean_absolute_error: 0.3966
Epoch 122/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1066 - mean_absolute_error: 0.2215 - val_loss: 0.4498 - val_mean_absolute_error: 0.4120
Epoch 123/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1154 - mean_absolute_error: 0.2299 - val_loss: 0.4925 - val_mean_absolute_error: 0.4311
Epoch 124/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1039 - mean_absolute_error: 0.2192 - val_loss: 0.4785 - val_mean_absolute_error: 0.4244
Epoch 125/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1026 - mean_absolute_error: 0.2177 - val_loss: 0.4770 - val_mean_absolute_error: 0.4243
Epoch 126/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1021 - mean_absolute_error: 0.2173 - val_loss: 0.4744 - val_mean_absolute_error: 0.4246
Epoch 127/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1037 - mean_absolute_error: 0.2188 - val_loss: 0.4721 - val_mean_absolute_error: 0.4204
Epoch 128/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1014 - mean_absolute_error: 0.2165 - val_loss: 0.4720 - val_mean_absolute_error: 0.4211
Epoch 129/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1020 - mean_absolute_error: 0.2171 - val_loss: 0.4770 - val_mean_absolute_error: 0.4241
Epoch 130/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1018 - mean_absolute_error: 0.2167 - val_loss: 0.4623 - val_mean_absolute_error: 0.4176
Epoch 131/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1043 - mean_absolute_error: 0.2189 - val_loss: 0.4724 - val_mean_absolute_error: 0.4209
Epoch 132/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1030 - mean_absolute_error: 0.2178 - val_loss: 0.4724 - val_mean_absolute_error: 0.4224
Epoch 133/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1005 - mean_absolute_error: 0.2153 - val_loss: 0.4636 - val_mean_absolute_error: 0.4142
Epoch 134/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0993 - mean_absolute_error: 0.2139 - val_loss: 0.4771 - val_mean_absolute_error: 0.4232
Epoch 135/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1000 - mean_absolute_error: 0.2147 - val_loss: 0.4614 - val_mean_absolute_error: 0.4147
Epoch 136/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1531 - mean_absolute_error: 0.2571 - val_loss: 0.4503 - val_mean_absolute_error: 0.4667
Epoch 137/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1222 - mean_absolute_error: 0.2364 - val_loss: 0.4366 - val_mean_absolute_error: 0.4128
Epoch 138/200
100/100 [==============================] - 1s 8ms/step - loss: 0.1026 - mean_absolute_error: 0.2174 - val_loss: 0.4717 - val_mean_absolute_error: 0.4231
Epoch 139/200
100/100 [==============================] - 1s 8ms/step - loss: 0.0991 - mean_absolute_error: 0.2138 - val_loss: 0.4768 - val_mean_absolute_error: 0.4251
Epoch 140/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0978 - mean_absolute_error: 0.2121 - val_loss: 0.4778 - val_mean_absolute_error: 0.4234
Epoch 141/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0987 - mean_absolute_error: 0.2132 - val_loss: 0.4751 - val_mean_absolute_error: 0.4241
Epoch 142/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0969 - mean_absolute_error: 0.2113 - val_loss: 0.4787 - val_mean_absolute_error: 0.4236
Epoch 143/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0972 - mean_absolute_error: 0.2115 - val_loss: 0.4852 - val_mean_absolute_error: 0.4279
Epoch 144/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0973 - mean_absolute_error: 0.2115 - val_loss: 0.4853 - val_mean_absolute_error: 0.4268
Epoch 145/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1050 - mean_absolute_error: 0.2193 - val_loss: 0.5068 - val_mean_absolute_error: 0.4380
Epoch 146/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1009 - mean_absolute_error: 0.2151 - val_loss: 0.4687 - val_mean_absolute_error: 0.4187
Epoch 147/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0960 - mean_absolute_error: 0.2099 - val_loss: 0.4710 - val_mean_absolute_error: 0.4206
Epoch 148/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0959 - mean_absolute_error: 0.2099 - val_loss: 0.4687 - val_mean_absolute_error: 0.4246
Epoch 149/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1028 - mean_absolute_error: 0.2161 - val_loss: 0.4726 - val_mean_absolute_error: 0.4227
Epoch 150/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0968 - mean_absolute_error: 0.2110 - val_loss: 0.4620 - val_mean_absolute_error: 0.4151
Epoch 151/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0965 - mean_absolute_error: 0.2104 - val_loss: 0.4736 - val_mean_absolute_error: 0.4217
Epoch 152/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0940 - mean_absolute_error: 0.2076 - val_loss: 0.4682 - val_mean_absolute_error: 0.4176
Epoch 153/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0946 - mean_absolute_error: 0.2083 - val_loss: 0.4726 - val_mean_absolute_error: 0.4219
Epoch 154/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0946 - mean_absolute_error: 0.2084 - val_loss: 0.4719 - val_mean_absolute_error: 0.4222
Epoch 155/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1285 - mean_absolute_error: 0.2380 - val_loss: 0.4705 - val_mean_absolute_error: 0.4223
Epoch 156/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1099 - mean_absolute_error: 0.2225 - val_loss: 0.4695 - val_mean_absolute_error: 0.4235
Epoch 157/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0955 - mean_absolute_error: 0.2088 - val_loss: 0.4600 - val_mean_absolute_error: 0.4161
Epoch 158/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0924 - mean_absolute_error: 0.2055 - val_loss: 0.4561 - val_mean_absolute_error: 0.4148
Epoch 159/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1018 - mean_absolute_error: 0.2153 - val_loss: 0.4540 - val_mean_absolute_error: 0.4146
Epoch 160/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0933 - mean_absolute_error: 0.2068 - val_loss: 0.4564 - val_mean_absolute_error: 0.4130
Epoch 161/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0920 - mean_absolute_error: 0.2052 - val_loss: 0.4549 - val_mean_absolute_error: 0.4144
Epoch 162/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0921 - mean_absolute_error: 0.2053 - val_loss: 0.4637 - val_mean_absolute_error: 0.4188
Epoch 163/200
100/100 [==============================] - 1s 6ms/step - loss: 0.0958 - mean_absolute_error: 0.2091 - val_loss: 0.4571 - val_mean_absolute_error: 0.4161
Epoch 164/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0924 - mean_absolute_error: 0.2055 - val_loss: 0.4637 - val_mean_absolute_error: 0.4176
Epoch 165/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0911 - mean_absolute_error: 0.2041 - val_loss: 0.4666 - val_mean_absolute_error: 0.4187
Epoch 166/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0910 - mean_absolute_error: 0.2040 - val_loss: 0.4544 - val_mean_absolute_error: 0.4147
Epoch 167/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0910 - mean_absolute_error: 0.2040 - val_loss: 0.4569 - val_mean_absolute_error: 0.4165
Epoch 168/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0905 - mean_absolute_error: 0.2035 - val_loss: 0.4684 - val_mean_absolute_error: 0.4217
Epoch 169/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0901 - mean_absolute_error: 0.2028 - val_loss: 0.4525 - val_mean_absolute_error: 0.4131
Epoch 170/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0899 - mean_absolute_error: 0.2027 - val_loss: 0.4638 - val_mean_absolute_error: 0.4185
Epoch 171/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0911 - mean_absolute_error: 0.2040 - val_loss: 0.4582 - val_mean_absolute_error: 0.4140
Epoch 172/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0900 - mean_absolute_error: 0.2026 - val_loss: 0.4715 - val_mean_absolute_error: 0.4194
Epoch 173/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0891 - mean_absolute_error: 0.2017 - val_loss: 0.4694 - val_mean_absolute_error: 0.4216
Epoch 174/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0890 - mean_absolute_error: 0.2016 - val_loss: 0.4651 - val_mean_absolute_error: 0.4186
Epoch 175/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0887 - mean_absolute_error: 0.2013 - val_loss: 0.4761 - val_mean_absolute_error: 0.4256
Epoch 176/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0885 - mean_absolute_error: 0.2011 - val_loss: 0.4634 - val_mean_absolute_error: 0.4172
Epoch 177/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1048 - mean_absolute_error: 0.2154 - val_loss: 0.4389 - val_mean_absolute_error: 0.4373
Epoch 178/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1114 - mean_absolute_error: 0.2213 - val_loss: 0.4517 - val_mean_absolute_error: 0.4174
Epoch 179/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0944 - mean_absolute_error: 0.2074 - val_loss: 0.4595 - val_mean_absolute_error: 0.4158
Epoch 180/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0908 - mean_absolute_error: 0.2031 - val_loss: 0.4689 - val_mean_absolute_error: 0.4193
Epoch 181/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0881 - mean_absolute_error: 0.2004 - val_loss: 0.4775 - val_mean_absolute_error: 0.4258
Epoch 182/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0878 - mean_absolute_error: 0.2001 - val_loss: 0.4661 - val_mean_absolute_error: 0.4183
Epoch 183/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0875 - mean_absolute_error: 0.1997 - val_loss: 0.4691 - val_mean_absolute_error: 0.4218
Epoch 184/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0886 - mean_absolute_error: 0.2013 - val_loss: 0.4734 - val_mean_absolute_error: 0.4219
Epoch 185/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0888 - mean_absolute_error: 0.2009 - val_loss: 0.4893 - val_mean_absolute_error: 0.4363
Epoch 186/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0883 - mean_absolute_error: 0.2006 - val_loss: 0.4702 - val_mean_absolute_error: 0.4208
Epoch 187/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0869 - mean_absolute_error: 0.1990 - val_loss: 0.4735 - val_mean_absolute_error: 0.4237
Epoch 188/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0858 - mean_absolute_error: 0.1977 - val_loss: 0.4594 - val_mean_absolute_error: 0.4172
Epoch 189/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0869 - mean_absolute_error: 0.1993 - val_loss: 0.4597 - val_mean_absolute_error: 0.4166
Epoch 190/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0868 - mean_absolute_error: 0.1990 - val_loss: 0.4734 - val_mean_absolute_error: 0.4221
Epoch 191/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0856 - mean_absolute_error: 0.1974 - val_loss: 0.4524 - val_mean_absolute_error: 0.4128
Epoch 192/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1176 - mean_absolute_error: 0.2283 - val_loss: 0.4655 - val_mean_absolute_error: 0.4180
Epoch 193/200
100/100 [==============================] - 1s 7ms/step - loss: 0.1072 - mean_absolute_error: 0.2183 - val_loss: 0.4679 - val_mean_absolute_error: 0.4197
Epoch 194/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0869 - mean_absolute_error: 0.1993 - val_loss: 0.4858 - val_mean_absolute_error: 0.4281
Epoch 195/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0854 - mean_absolute_error: 0.1974 - val_loss: 0.4713 - val_mean_absolute_error: 0.4216
Epoch 196/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0846 - mean_absolute_error: 0.1965 - val_loss: 0.4761 - val_mean_absolute_error: 0.4233
Epoch 197/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0842 - mean_absolute_error: 0.1959 - val_loss: 0.4845 - val_mean_absolute_error: 0.4305
Epoch 198/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0845 - mean_absolute_error: 0.1963 - val_loss: 0.4744 - val_mean_absolute_error: 0.4221
Epoch 199/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0837 - mean_absolute_error: 0.1955 - val_loss: 0.4740 - val_mean_absolute_error: 0.4241
Epoch 200/200
100/100 [==============================] - 1s 7ms/step - loss: 0.0839 - mean_absolute_error: 0.1954 - val_loss: 0.4739 - val_mean_absolute_error: 0.4231
28/28 [==============================] - 0s 2ms/step - loss: 0.4739 - mean_absolute_error: 0.4231
#+end_example
[[file:./.ob-jupyter/e4514c1dc9facd2232d8c68e10e74339da1cd160.png]]
:END:

#+begin_src python3
multi_window.val
#+end_src

#+RESULTS:
: <MapDataset element_spec=(TensorSpec(shape=(None, 24, 5), dtype=tf.float32, name=None), TensorSpec(shape=(None, 24, 5), dtype=tf.float32, name=None))>

,#+begin_src python3
multi_val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)
multi_performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)
multi_window.plot(feedback_model)
#+end_src

#+RESULTS:
:RESULTS:
: 28/28 [==============================] - 0s 2ms/step - loss: 0.4739 - mean_absolute_error: 0.4231
[[file:./.ob-jupyter/e4514c1dc9facd2232d8c68e10e74339da1cd160.png]]
:END:
